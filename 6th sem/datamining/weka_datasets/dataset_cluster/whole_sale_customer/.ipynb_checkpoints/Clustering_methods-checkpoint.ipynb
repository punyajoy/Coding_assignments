{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering as AGC\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import normalize\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "str1='classifier_ranker'\n",
    "#str1='total_dataset'\n",
    "pathlib.Path(str1).mkdir(parents=True, exist_ok=True) \n",
    "df=pd.read_csv('Wholesale+classifier_ranker.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import pandas as pd \n",
    "from sklearn.cluster import k_means\n",
    "# nc is number of clusters\n",
    "# to be implemented without the use of any libraries (from the scratch)\n",
    "\n",
    "def compute_s(i, x, labels, clusters):\n",
    "    norm_c= len(clusters)\n",
    "    s = 0\n",
    "    for x in clusters:\n",
    "        \n",
    "        s += distance.euclidean(x, clusters[i])\n",
    "    return s\n",
    "\n",
    "def compute_Rij(i, j, x, labels, clusters, nc):\n",
    "    Rij = 0\n",
    "    try:\n",
    "        d = distance.euclidean(clusters[i],clusters[j])\n",
    "        Rij = (compute_s(i, x, labels, clusters) + compute_s(j, x, labels, clusters))/d\n",
    "    \n",
    "    except:\n",
    "        Rij = 0    \n",
    "    return Rij\n",
    "\n",
    "def compute_R(i, x, labels, clusters, nc): \n",
    "    list_r = []\n",
    "    for i in range(nc):\n",
    "        for j in range(nc):\n",
    "            if(i!=j):\n",
    "                temp = compute_Rij(i, j, x, labels, clusters, nc)\n",
    "                list_r.append(temp)\n",
    "\n",
    "    return max(list_r)\n",
    "\n",
    "def compute_DB_index(x, labels, clusters, nc):\n",
    "\n",
    "    sigma_R = 0.0\n",
    "    for i in range(nc):\n",
    "        sigma_R = sigma_R + compute_R(i, x, labels, clusters, nc)\n",
    "\n",
    "    DB_index = float(sigma_R)/float(nc)\n",
    "    return DB_index\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalize_to_smallest_integers(labels):\n",
    "    \"\"\"Normalizes a list of integers so that each number is reduced to the minimum possible integer, maintaining the order of elements.\n",
    "\n",
    "    :param labels: the list to be normalized\n",
    "    :returns: a numpy.array with the values normalized as the minimum integers between 0 and the maximum possible value.\n",
    "    \"\"\"\n",
    "\n",
    "    max_v = len(set(labels)) if -1 not in labels else len(set(labels)) - 1\n",
    "    sorted_labels = np.sort(np.unique(labels))\n",
    "    unique_labels = range(max_v)\n",
    "    new_c = np.zeros(len(labels), dtype=np.int32)\n",
    "\n",
    "    for i, clust in enumerate(sorted_labels):\n",
    "        new_c[labels == clust] = unique_labels[i]\n",
    "\n",
    "    return new_c\n",
    "\n",
    "\n",
    "def dunn(labels, distances):\n",
    "    \"\"\"\n",
    "    Dunn index for cluster validation (the bigger, the better)\n",
    "    \n",
    "    .. math:: D = \\\\min_{i = 1 \\\\ldots n_c; j = i + 1\\ldots n_c} \\\\left\\\\lbrace \\\\frac{d \\\\left( c_i,c_j \\\\right)}{\\\\max_{k = 1 \\\\ldots n_c} \\\\left(diam \\\\left(c_k \\\\right) \\\\right)} \\\\right\\\\rbrace\n",
    "    \n",
    "    where :math:`d(c_i,c_j)` represents the distance between\n",
    "    clusters :math:`c_i` and :math:`c_j`, given by the distances between its\n",
    "    two closest data points, and :math:`diam(c_k)` is the diameter of cluster\n",
    "    :math:`c_k`, given by the distance between its two farthest data points.\n",
    "    \n",
    "    The bigger the value of the resulting Dunn index, the better the clustering\n",
    "    result is considered, since higher values indicate that clusters are\n",
    "    compact (small :math:`diam(c_k)`) and far apart.\n",
    "\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    \n",
    "    .. [Kovacs2005] Kovács, F., Legány, C., & Babos, A. (2005). Cluster validity measurement techniques. 6th International Symposium of Hungarian Researchers on Computational Intelligence.\n",
    "    \"\"\"\n",
    "\n",
    "    labels = normalize_to_smallest_integers(labels)\n",
    "\n",
    "    unique_cluster_distances = np.unique(min_cluster_distances(labels, distances))\n",
    "    max_diameter = max(diameter(labels, distances))\n",
    "\n",
    "    if np.size(unique_cluster_distances) > 1:\n",
    "        return unique_cluster_distances[1] / max_diameter\n",
    "    else:\n",
    "        return unique_cluster_distances[0] / max_diameter\n",
    "\n",
    "\n",
    "def min_cluster_distances(labels, distances):\n",
    "    \"\"\"Calculates the distances between the two nearest points of each cluster.\n",
    "\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    \"\"\"\n",
    "    labels = normalize_to_smallest_integers(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "\n",
    "    min_distances = np.zeros((n_unique_labels, n_unique_labels))\n",
    "    for i in np.arange(0, len(labels) - 1):\n",
    "        for ii in np.arange(i + 1, len(labels)):\n",
    "            if labels[i] != labels[ii] and distances[i, ii] > min_distances[labels[i], labels[ii]]:\n",
    "                min_distances[labels[i], labels[ii]] = min_distances[labels[ii], labels[i]] = distances[i, ii]\n",
    "    return min_distances\n",
    "\n",
    "\n",
    "def diameter(labels, distances):\n",
    "    \"\"\"Calculates cluster diameters (the distance between the two farthest data points in a cluster)\n",
    "\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :returns:\n",
    "    \"\"\"\n",
    "    labels = normalize_to_smallest_integers(labels)\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    diameters = np.zeros(n_clusters)\n",
    "\n",
    "    for i in np.arange(0, len(labels) - 1):\n",
    "        for ii in np.arange(i + 1, len(labels)):\n",
    "            if labels[i] == labels[ii] and distances[i, ii] > diameters[labels[i]]:\n",
    "                diameters[labels[i]] = distances[i, ii]\n",
    "    return diameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=df.loc[:, df.columns != 'Channel'].as_matrix()\n",
    "X=normalize(X)\n",
    "y=df[['Channel']].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "db_index=[]\n",
    "dunn_index=[]\n",
    "slhte_index=[]\n",
    "rand_indlist=[]\n",
    "acc_list=[]\n",
    "precision_list=[]\n",
    "recall_list=[]\n",
    "fscore_list=[]\n",
    "str2='Kmeans'\n",
    "pathlib.Path(str1+'/'+str2).mkdir(parents=True, exist_ok=True) \n",
    "for i in range(2,15):\n",
    "    clf=KMeans(n_clusters=i, random_state=0).fit(X)\n",
    "    \n",
    "    #internal_measures\n",
    "    index_db_val = compute_DB_index(X,clf.labels_,clf.cluster_centers_, i)\n",
    "    db_index.append(index_db_val)\n",
    "    index_dunn = dunn(clf.labels_,euclidean_distances(X))\n",
    "    dunn_index.append(index_dunn)\n",
    "    index_slhte = silhouette_score(X,clf.labels_)\n",
    "    slhte_index.append(index_slhte)\n",
    "    \n",
    "    #external_measures\n",
    "    precision,recall,fcore,support=precision_recall_fscore_support(y,clf.labels_,average='weighted')\n",
    "    acuracy_=accuracy_score(y, clf.labels_)\n",
    "    rand_score=adjusted_rand_score(y.reshape(440,), clf.labels_)\n",
    "    rand_indlist.append(rand_score)\n",
    "    acc_list.append(acuracy_)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    fscore_list.append(fcore)\n",
    "import matplotlib.pyplot as plt    \n",
    "t=np.arange(2,15,1)\n",
    "plt.clf()\n",
    "plt.plot(t, dunn_index, 'r--')\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('dunn_index')\n",
    "plt.savefig(str1+'/'+str2+'/'+'dunn_index.png')\n",
    "plt.clf()\n",
    "plt.plot(t, db_index, 'b^')\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('db_index')\n",
    "plt.savefig(str1+'/'+str2+'/'+'dB_index.png')\n",
    "plt.clf()\n",
    "plt.plot(t, slhte_index, 'gs')\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('silhouette_index')\n",
    "plt.savefig(str1+'/'+str2+'/'+'silhouette_index.png')\n",
    "plt.clf()\n",
    "plt.plot(t, precision_list, 'g+')\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('precision_list')\n",
    "plt.savefig(str1+'/'+str2+'/'+'precision.png')\n",
    "plt.clf()\n",
    "plt.plot(t, acc_list, 'r--')\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('acc_list')\n",
    "plt.savefig(str1+'/'+str2+'/'+'accuracy.png')\n",
    "plt.clf()\n",
    "plt.plot(t, recall_list, 'r+')\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('recall_list')\n",
    "plt.savefig(str1+'/'+str2+'/'+'recall.png')\n",
    "plt.clf()\n",
    "plt.plot(t, fscore_list, 'r+')\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('fscore_list')\n",
    "plt.savefig(str1+'/'+str2+'/'+'fscore.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "db_index=[]\n",
    "dunn_index=[]\n",
    "slhte_index=[]\n",
    "rand_indlist=[]\n",
    "acc_list=[]\n",
    "precision_list=[]\n",
    "recall_list=[]\n",
    "fscore_list=[]\n",
    "str2='AGC_euc_ward'\n",
    "pathlib.Path(str1+'/'+str2).mkdir(parents=True, exist_ok=True) \n",
    "for i in range(2,15):\n",
    "    clf = AGC(n_clusters=i, affinity='euclidean', linkage='ward').fit(X)\n",
    "    \n",
    "    #internal_measures\n",
    "    index_dunn = dunn(clf.labels_,euclidean_distances(X))\n",
    "    dunn_index.append(index_dunn)\n",
    "    index_slhte = silhouette_score(X,clf.labels_)\n",
    "    slhte_index.append(index_slhte)\n",
    "    \n",
    "    #external_measures\n",
    "    precision,recall,fcore,support=precision_recall_fscore_support(y,clf.labels_,average='weighted')\n",
    "    acuracy_=accuracy_score(y, clf.labels_)\n",
    "    rand_score=adjusted_rand_score(y.reshape(440,), clf.labels_)\n",
    "    rand_indlist.append(rand_score)\n",
    "    acc_list.append(acuracy_)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    fscore_list.append(fcore)\n",
    "import matplotlib.pyplot as plt    \n",
    "t=np.arange(2,15,1)\n",
    "plt.clf()\n",
    "plt.plot(t, dunn_index, 'r--')\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('dunn_index')\n",
    "plt.savefig(str1+'/'+str2+'/'+'dunn_index.png')\n",
    "plt.clf()\n",
    "plt.plot(t, slhte_index, 'gs')\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('silhouette_index')\n",
    "plt.savefig(str1+'/'+str2+'/'+'silhouette_index.png')\n",
    "plt.clf()\n",
    "plt.plot(t, precision_list, 'g+')\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('precision_list')\n",
    "plt.savefig(str1+'/'+str2+'/'+'precision.png')\n",
    "plt.clf()\n",
    "plt.plot(t, acc_list, 'r--')\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('acc_list')\n",
    "plt.savefig(str1+'/'+str2+'/'+'accuracy.png')\n",
    "plt.clf()\n",
    "plt.plot(t, recall_list, 'r+')\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('recall_list')\n",
    "plt.savefig(str1+'/'+str2+'/'+'recall.png')\n",
    "plt.clf()\n",
    "plt.plot(t, fscore_list, 'r+')\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('fscore_list')\n",
    "plt.savefig(str1+'/'+str2+'/'+'fscore.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import skfuzzy\n",
    "db_index=[]\n",
    "dunn_index=[]\n",
    "slhte_index=[]\n",
    "rand_indlist=[]\n",
    "acc_list=[]\n",
    "precision_list=[]\n",
    "recall_list=[]\n",
    "fscore_list=[]\n",
    "str2='Fuzzy-C-means-2(m)'\n",
    "pathlib.Path(str1+'/'+str2).mkdir(parents=True, exist_ok=True) \n",
    "for i in range(2,15):\n",
    "    cntr, u, u0, d, jm, p, fpc = skfuzzy.cluster.cmeans(\n",
    "        X.reshape(X.shape[1],X.shape[0]), i, 2, error=0.005, maxiter=1000, init=None)\n",
    "    labels=np.argmax(u,axis=0)\n",
    "    #internal_measures\n",
    "    index_db_val = compute_DB_index(X,labels,cntr, i)\n",
    "    db_index.append(index_db_val)\n",
    "    index_dunn = dunn(labels,euclidean_distances(X))\n",
    "    dunn_index.append(index_dunn)\n",
    "    index_slhte = silhouette_score(X,labels)\n",
    "    slhte_index.append(index_slhte)\n",
    "    \n",
    "    #external_measures\n",
    "    precision,recall,fcore,support=precision_recall_fscore_support(y,labels,average='weighted')\n",
    "    acuracy_=accuracy_score(y, labels)\n",
    "    rand_score=adjusted_rand_score(y.reshape(440,), labels)\n",
    "    rand_indlist.append(rand_score)\n",
    "    acc_list.append(acuracy_)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    fscore_list.append(fcore)\n",
    "import matplotlib.pyplot as plt    \n",
    "t=np.arange(2,15,1)\n",
    "plt.clf()\n",
    "plt.plot(t, dunn_index, 'r--')\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('dunn_index')\n",
    "plt.savefig(str1+'/'+str2+'/'+'dunn_index.png')\n",
    "plt.clf()\n",
    "plt.plot(t, db_index, 'b^')\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('db_index')\n",
    "plt.savefig(str1+'/'+str2+'/'+'dB_index.png')\n",
    "plt.clf()\n",
    "plt.plot(t, slhte_index, 'gs')\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('silhouette_index')\n",
    "plt.savefig(str1+'/'+str2+'/'+'silhouette_index.png')\n",
    "plt.clf()\n",
    "plt.plot(t, precision_list, 'g+')\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('precision_list')\n",
    "plt.savefig(str1+'/'+str2+'/'+'precision.png')\n",
    "plt.clf()\n",
    "plt.plot(t, acc_list, 'r--')\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('acc_list')\n",
    "plt.savefig(str1+'/'+str2+'/'+'accuracy.png')\n",
    "plt.clf()\n",
    "plt.plot(t, recall_list, 'r+')\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('recall_list')\n",
    "plt.savefig(str1+'/'+str2+'/'+'recall.png')\n",
    "plt.clf()\n",
    "plt.plot(t, fscore_list, 'r+')\n",
    "plt.xlabel('k-value')\n",
    "plt.ylabel('fscore_list')\n",
    "plt.savefig(str1+'/'+str2+'/'+'fscore.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Punyajoy Saha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "db_index=[]\n",
    "dunn_index=[]\n",
    "slhte_index=[]\n",
    "rand_indlist=[]\n",
    "acc_list=[]\n",
    "precision_list=[]\n",
    "recall_list=[]\n",
    "fscore_list=[]\n",
    "str2='Mean_shift'\n",
    "pathlib.Path(str1+'/'+str2).mkdir(parents=True, exist_ok=True) \n",
    "for i in np.arange(0.1,0.6,0.05):\n",
    "    ms = MeanShift(bandwidth=i, bin_seeding=True)\n",
    "    ms.fit(X)\n",
    "    #internal_measures\n",
    "    index_db_val = compute_DB_index(X,ms.labels_,ms.cluster_centers_, len(np.unique(ms.labels_)))\n",
    "    db_index.append(index_db_val)\n",
    "    index_dunn = dunn(ms.labels_,euclidean_distances(X))\n",
    "    dunn_index.append(index_dunn)\n",
    "    index_slhte = silhouette_score(X,ms.labels_)\n",
    "    slhte_index.append(index_slhte)\n",
    "    \n",
    "    #external_measures\n",
    "    precision,recall,fcore,support=precision_recall_fscore_support(y,ms.labels_,average='weighted')\n",
    "    acuracy_=accuracy_score(y, ms.labels_)\n",
    "    rand_score=adjusted_rand_score(y.reshape(440,), ms.labels_)\n",
    "    rand_indlist.append(rand_score)\n",
    "    acc_list.append(acuracy_)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    fscore_list.append(fcore)\n",
    "import matplotlib.pyplot as plt    \n",
    "t=np.arange(0.1,0.6,0.05)\n",
    "plt.clf()\n",
    "plt.plot(t, dunn_index, 'r--')\n",
    "plt.xlabel('bandwidth_value')\n",
    "plt.ylabel('dunn_index')\n",
    "plt.savefig(str1+'/'+str2+'/'+'dunn_index.png')\n",
    "plt.clf()\n",
    "plt.plot(t, db_index, 'b^')\n",
    "plt.xlabel('bandwidth_value')\n",
    "plt.ylabel('db_index')\n",
    "plt.savefig(str1+'/'+str2+'/'+'dB_index.png')\n",
    "plt.clf()\n",
    "plt.plot(t, slhte_index, 'gs')\n",
    "plt.xlabel('bandwidth_value')\n",
    "plt.ylabel('silhouette_index')\n",
    "plt.savefig(str1+'/'+str2+'/'+'silhouette_index.png')\n",
    "plt.clf()\n",
    "plt.plot(t, precision_list, 'g+')\n",
    "plt.xlabel('bandwidth_value')\n",
    "plt.ylabel('precision_list')\n",
    "plt.savefig(str1+'/'+str2+'/'+'precision.png')\n",
    "plt.clf()\n",
    "plt.plot(t, acc_list, 'r--')\n",
    "plt.xlabel('bandwidth_value')\n",
    "plt.ylabel('acc_list')\n",
    "plt.savefig(str1+'/'+str2+'/'+'accuracy.png')\n",
    "plt.clf()\n",
    "plt.plot(t, recall_list, 'r+')\n",
    "plt.xlabel('bandwidth_value')\n",
    "plt.ylabel('recall_list')\n",
    "plt.savefig(str1+'/'+str2+'/'+'recall.png')\n",
    "plt.clf()\n",
    "plt.plot(t, fscore_list, 'r+')\n",
    "plt.xlabel('bandwidth_value')\n",
    "plt.ylabel('fscore_list')\n",
    "plt.savefig(str1+'/'+str2+'/'+'fscore.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5500000000000002"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
